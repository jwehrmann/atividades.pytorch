{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from collections import defaultdict\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O código da célula abaixo contém funções para efetuar a carga dos dados, treinamento teste dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root='../data', \n",
    "            train=True, \n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        ),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=datasets.MNIST(\n",
    "            root='../data', \n",
    "            train=False, \n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        ),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train_epoch(\n",
    "        model, \n",
    "        device, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        epoch, \n",
    "        log_interval\n",
    "    ):\n",
    "    model.train()\n",
    "    history = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        history['loss'].append(loss.item())\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(\n",
    "        model, \n",
    "        device, \n",
    "        criterion, \n",
    "        test_loader\n",
    "    ):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        device,\n",
    "        lr,\n",
    "        nb_epochs=3,\n",
    "        log_interval=100,\n",
    "    ):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for epoch in range(1, nb_epochs + 1):\n",
    "        print('\\n* * * Training * * *')\n",
    "        train_epoch(\n",
    "            model=model, \n",
    "            device=device, \n",
    "            train_loader=train_loader, \n",
    "            optimizer=optimizer, \n",
    "            criterion=criterion, \n",
    "            epoch=epoch, \n",
    "            log_interval=log_interval\n",
    "        )\n",
    "        print('\\n* * * Evaluating * * *')\n",
    "        acc = test(model, device, criterion, test_loader)   \n",
    "        history['val_acc'].append(acc)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def check_input(model, device):\n",
    "    dummy_data = torch.zeros(5, 1, 28, 28).to(device)\n",
    "    dummy_pred = model(dummy_data)        \n",
    "    assert dummy_pred.shape == (5, 10), '\\nOutput expected: (batch_size, 10) \\nOutput found   : {}'.format(dummy_pred.shape)\n",
    "    print('Passed')\n",
    "    return dummy_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parâmetros que você pode definir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device_name = 'cpu'\n",
    "nb_epochs = 3\n",
    "log_interval = 500\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conferência dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loaders(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Train size: ', \n",
    "    train_loader.dataset.train_data.shape, \n",
    "    train_loader.dataset.train_labels.shape\n",
    ")\n",
    "print(\n",
    "    'Test size : ', \n",
    "    test_loader.dataset.test_data.shape, \n",
    "    test_loader.dataset.test_labels.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 5)\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(train_loader.dataset.train_data[i], cmap='gray')\n",
    "    ax.set_title(train_loader.dataset.train_labels[i].item())\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = next(iter(train_loader))\n",
    "print('Instance Example: ', instance[0].shape, instance[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seu trabalho começa aqui:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implemente aqui sua primeira rede convolucional  \n",
    "\n",
    "Sua ConvNet deve ser capaz de classificar as imagens do MNIST. Lembre-se que as imagens do MNIST tem apenas 1 canal, isto é, elas são em escala de cinza (e não RBG!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitetura:\n",
    "* Input: (1, 28, 28)\n",
    "* Conv(32, 3)\n",
    "* MaxPool(2)\n",
    "* Conv(64, 3)\n",
    "* MaxPool(2)\n",
    "* Flatten \n",
    "* Linear(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Verifique se a saída do seu modelo está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Treine seu modelo por uma ou mais épocas. \n",
    "\n",
    "Você deve conseguir ~99% de acurácia na terceira época. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implemente aqui outra rede convolucional  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitetura:\n",
    "* Input: (1, 28, 28)\n",
    "* Conv(32, 5)\n",
    "* MaxPool(2)\n",
    "* Conv(64, 5)\n",
    "* MaxPool(2)\n",
    "* Flatten \n",
    "* Linear(10)\n",
    "   \n",
    "IMPORTANTE: Faça com que o maxpooling seja a única camada que reduz as dimensões espaciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Verifique se a saída do seu modelo está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Treine seu modelo por uma ou mais épocas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implemente aqui mais uma rede convolucional  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitetura:\n",
    "* Input: (1, 28, 28)\n",
    "* Conv(32, 5)\n",
    "* MaxPool(2)\n",
    "* Conv(64, 3)\n",
    "* MaxPool(2)\n",
    "* Conv(128, 3)\n",
    "* GlobalPooling\n",
    "* Linear(10)\n",
    "   \n",
    "IMPORTANTE: Faça com que o maxpooling seja a única camada que reduz as dimensões espaciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Verifique se a saída do seu modelo está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Treine seu modelo por uma ou mais épocas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implemente a arquitetura de rede convolucional conforme segue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitetura:\n",
    "* Input: (1, 28, 28)\n",
    "* Conv(32, 5, stride=2)\n",
    "* Conv(64, 3)\n",
    "* Conv(16, 1) # Redução da dimensionalidade dos canais (bottleneck)\n",
    "* MaxPool(2)\n",
    "* Conv(128, 3)\n",
    "* Conv(64, 1)  # Redução da dimensionalidade dos canais (bottleneck)\n",
    "* Conv(256, 3)\n",
    "* GlobalPooling\n",
    "* Linear(10)\n",
    "   \n",
    "IMPORTANTE: Faça com que a primeira convolução e o maxpooling sejam as únicas camadas que reduzem as dimensões espaciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Verifique se a saída do seu modelo está correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Treine seu modelo por uma ou mais épocas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Atualize a rede convolucional anterior para usar o container nn.Sequential()\n",
    "\n",
    "A arquitetura da rede pode ser exatamente igual à rede anterior, porém, agora use o nn.Sequential para criar as camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetSeq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetSeq, self).__init__()        \n",
    "        \n",
    "    def forward(self, x):   \n",
    "        \n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ConvNetSeq().to(device)\n",
    "print(model)\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Crie uma nova rede substituindo as camadas de convolução da sua primeira rede por blocos Inception.  \n",
    "\n",
    "Detalhes:\n",
    "\n",
    "1. Crie um novo módulo (classe que herda do nn.Module) chamado de InceptionModule. \n",
    "2. Nesse módulo você deverá criar camadas convolucionais com filtros 1x1, 3x3 e 5x5 paralelamente. No final, concatene o resultado, e aplique mais uma convolução 1x1 para reduzir a dimensionalidade ao tamanho original. \n",
    "2. Atualize sua rede convolucional substituindo as camadas de convolução pelo seu bloco Inception. \n",
    "3. Treine o modelo e reporte a acurácia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(InceptionModule, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return out\n",
    "\n",
    "model = InceptionModule(1, 32)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(InceptionNet, self).__init__()            \n",
    "        # Use aqui o module Inception\n",
    "    def forward(self, x):        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionNet(device=device).to(device)\n",
    "dummy_pred = check_input(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = train(model, train_loader, test_loader, device, lr, nb_epochs, log_interval)\n",
    "print('Final acc: {:.2f}%'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
